# Emosense:Listening Beyond Words

- # üîçProblem Statement
    To develop a robust emotion recognition system utilizing machine learning techniques on the CREMA-D dataset to classify various emotions expressed in audio recordings accurately.
- # üìñProblem Definition
    Emotion detection from speech is the task of recognizing the emotional state conveyed by an individual through their speech. This involves analyzing different acoustic features of the speech signal, such as pitch, intensity, and duration, as well as linguistic features and contextual information, to infer the underlying emotional state.By analyzing these features, we can better understand how emotions are conveyed through speech and use this information to improve communication and interaction between humans and machines. This has many applications in fields such as mental health, education, and customer service, where accurate identification of emotions is crucial for effective 
communication
- # üíºCREMA-D
     The Crema-D dataset, short for the CrowdEmotion Multimodal Database, is a valuable resource in the field of affective computing and emotion recognition research. It comprises a diverse collection of audiovisual recordings featuring actors expressing a wide range of emotions, including happiness, sadness, anger, fear, disgust, and surprise. With over 7,000 instances across more than 90 actors, Crema-D provides researchers with a rich and varied dataset for training and evaluating emotion recognition algorithms. Its multimodal nature, incorporating both facial expressions and vocal cues, makes it particularly useful for developing robust emotion detection models capable of understanding and interpreting human emotions across different modalities.
    
